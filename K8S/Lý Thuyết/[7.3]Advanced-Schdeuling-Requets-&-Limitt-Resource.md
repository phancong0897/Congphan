# Xác định các giá trị Requests và Limits resources cho containers

Khi Kubernetes lên lịch cho Pod ( tức là ra quyết định deploy pods với tài nguyên như thế nào và deploy trên node nào nếu là cụm kubernetes cluster), thì điều quan trọng là các container có đủ tài nguyên để hoạt động hiệu quả. Nếu bạn lên lịch cho một ứng dụng lớn trên một node có tài nguyên hạn chế, thì node đó có thể hết bộ nhớ hoặc tài nguyên CPU và mọi thứ ngừng hoạt động! Ngay cả trong quá trình vận hành, có rất nhiều nguyên nhân như cấu hình không tốt, do lỗi code,.. có thể dẫn đến việc ứng dụng của bạn sử dụng tài nguyên hơn mức cần thiết. Và dù lỗi xảy ra vì nguyên nhân gì, chúng ta cũng cần tìm ra các giải pháp để kiểm soát chúng một cách tốt nhất có thể. Một trong những giải pháp để bạn có thể giải quyết những vấn đề là bằng cách chỉ định các Request (yêu cầu) và Limit (giới hạn) tài nguyên.

### Request và Limit resource là gì và hoạt động như thế nào?

- Requests: Bảo đảm về lượng tài nguyên mà một pod trong workload sẽ được cấp. Mặc định các thuộc tính này sẽ để trống hoặc lấy theo yêu cầu mặc định của namespace (sẽ được đề cập sau). Tài nguyên request tối đa phải nhỏ hơn lượng tài nguyên mà một server mạnh nhất trong cluster có thể tải được.
    
    - Ví dụ: request: 100mCPU, 256MiB RAM mang ý nghĩa bạn sẽ luôn đảm bảo rằng k8s sẽ cấp cho bạn ít nhất 100 mCPU và 256MiB RAM. Hệ thống sẽ chỉ deploy pod của bạn trên node có đủ số lượng tài nguyên như trên. Tất nhiên kube-scheduler có đánh dấu lượng tài nguyên này đã bị chiếm dụng.
    
    - Giả sử bạn có 2 node, node 1 có 2 vCore và 8GiB RAM, node 2 có 4 vCore 16GiB RAM, nếu workload của bạn yêu cầu request: 2500mCPU, 8GiB RAM thì server sẽ chỉ deploy pod của workload này vào node 2.
    
    - Trong trường hợp cũng với cấu hình trên mà bạn yêu cầu tài nguyên request: 4000mCPU, 8GiB RAM, sẽ không có pod nào được deploy cả.

    - Pods sẽ nhận được số lượng bộ nhớ mà nó yêu cầu. Nếu vượt quá yêu cầu bộ nhớ, bộ nhớ có thể bị kill (loại bỏ) nếu một Pod khác nảy sinh nhu cầu với bộ nhớ này. Pods chỉ bị loại bỏ khi sử dụng ít bộ nhớ hơn yêu cầu nếu hệ thống quan trọng hoặc workload ưu tiên cần bộ nhớ.

    - Tương tự, container trong Pod được phân bổ số lượng CPU mà nó yêu cầu, nếu có sẵn. CPU cũng có thể được phân bổ các chu kỳ CPU bổ sung nếu các Pods hoặc công việc khác không cần tới tài nguyên có sẵn này.

    - Lưu ý: nếu tổng số yêu cầu Pod không có sẵn trên một node , thì Pod sẽ vẫn ở trạng thái “Pending state” (Đang chờ xử lý, tức là không chạy) cho đến khi các tài nguyên này khả dụng.

- Limits: Giới hạn lượng tài nguyên mà một pod trong workload sẽ được sử dụng
    
    - Ví dụ: limits: 1000mCPU, 2GiB RAM mang ý nghĩa rằng bạn chỉ có thể dùng tối đa 1 CPU và 2GiB RAM.

    - Giới hạn tài nguyên giúp bộ lập lịch Kubernetes xử lý tốt hơn sự tranh chấp tài nguyên. Khi một Pod sử dụng nhiều bộ nhớ hơn giới hạn của nó, các tiến trình của nó sẽ bị kernel loại bỏ (kill) để bảo vệ các ứng dụng khác trong cluster. Pods sẽ được điều chỉnh CPU khi vượt quá giới hạn CPU của chúng.
    
    - Nếu không có giới hạn nào được đặt, thì các pods có thể sử dụng bộ nhớ và CPU dư thừa khi khả dụng.
    
    - Nếu bạn chỉ định giới hạn CPU cho container nhưng không chỉ định yêu cầu CPU, Kubernetes sẽ tự động chỉ định yêu cầu CPU phù hợp với giới hạn. Tương tự, nếu một container chỉ định giới hạn bộ nhớ của riêng nó, nhưng không chỉ định yêu cầu bộ nhớ, Kubernetes sẽ tự động gán một yêu cầu bộ nhớ phù hợp với giới hạn.
    
    - Lưu ý: Điều quan trọng cần nhớ là Limits không bao giờ được thấp hơn Request. Bạn có thể thử đặt các giá trị như vậy, Kubernetes sẽ báo lỗi và không cho phép bạn chạy container của mình đâu 😄

- Một Pod là một khái niệm trừu tượng của Kubernetes, đại diện cho một nhóm gồm một hoặc nhiều ứng dụng containers (ví dụ như Docker hoặc rkt) và một số tài nguyên được chia sẻ cho các containers đó. Đến lượt mình, các pod có thể được triển khai và quản lý trên các node. Mỗi node trong một cụm Kubernetes có một lượng bộ nhớ (RAM) và CPU được phân bổ có thể được sử dụng để chạy các pods.

- Các yêu cầu và giới hạn tài nguyên là các tham số tùy chọn được chỉ định ở cấp độ của container. Kubernetes tính toán một yêu cầu và giới hạn của Pod bằng giá trị tổng hợp yêu cầu và giới hạn trên tất cả các container của nó. Kubernetes sau đó sẽ sử dụng các tham số này để lên lịch và quyết định phân bổ tài nguyên cho pods.

### Cơ chế deploy và kill của kube-scheduler

- Nếu bạn tạo một cluster k8s từ các công cụ như k3s, kubeadm hay từ các bên cung cấp nền tảng như AKS (của Azure), EKS (của Amazon) thì mặc định cluster đó sẽ sử dụng kube-scheduler để kiểm soát việc quản lý tài nguyên và deploy pod. Việc deploy hay kill pod của kube-scheduler đều hoạt động theo hai bước: Lọc và Chấm điểm.

- Trường hợp k8s deploy một pod vào cluster:

    - Bước Lọc: kube-scheduler sẽ liệt kê tất cả các node thỏa mãn điều kiện tối thiểu của workload (tức thỏa mãn lượng tài nguyên request). Nếu trong danh sách đó không có node nào, pod của bạn sẽ không bao giờ được deploy. Các pod chưa được deploy vẫn sẽ có cơ hội được chạy do kube-scheduler sẽ thực hiện việc chấm điểm này liên tục.
    
    - Bước Chấm điểm: kube-scheduler sẽ đánh giá các node thông qua nhiều tiêu chí khác nhau, từ đó đưa ra điểm số của node đó. kube-scheduler sẽ deploy vào node có điểm số cao nhất. Nếu có nhiều hơn 1 node có cùng một điểm số, pod sẽ được deploy ngẫu nhiên vào một trong các node đó.

- Còn trường hợp k8s cần kill pod để thu hồi lại tài nguyên:

    - Bước Lọc: kube-scheduler sẽ liệt kê tất cả các pod đang hoạt động trong node đang bị quá tải.
    
    - Bước Chấm điểm: kube-scheduler sẽ đánh giá các pod đó thông qua độ ưu tiên của pod (Pod Priority). Pod nào có điểm ưu tiên thấp hơn sẽ bị kill, các pod có điểm ưu tiên ngang nhau sẽ được kill ngẫu nhiên. Việc này sẽ lặp đi lặp lại đến khi server đủ tài nguyên thì thôi. Nhưng thông thường chúng ta thường bỏ quên mất tính năng này, nên các pod sẽ có điểm ưu tiên ngang nhau, vì vậy các pod sẽ bị chấm điểm thông qua lượng tài nguyên sử dụng. Các pod vượt quá tài nguyên yêu cầu càng nhiều, thì pod đó càng có khả năng bị kill. Việc này cũng sẽ lặp đi lặp lại đến khi server đủ tài nguyên thì thôi.
    
    - Trong trường hợp bạn có đặt mức độ ưu tiên cho pod, nếu bạn đặt cho pod của mình có độ ưu tiên cao hơn các pod hệ thống như kubelet, k8s có thể kill luôn các pod đó để thu hồi bộ nhớ. Tất nhiên việc này vừa có lợi điểm và hại điểm.
    
        - Điểm tốt: Node của bạn vẫn sẽ chạy và mọi thứ sẽ được deploy trở lại khi pod của bạn trả lại tài nguyên cho hệ thống.
    
        - Điểm không tốt: Khiến bạn lo lắng khi node được thông báo là đã crash và không có thông tin nào được cập nhật về. Tệ hơn nữa, node fail quá lâu sẽ khiến cho hệ thống bên thứ ba tưởng node của bạn đã sập (node tained), node sẽ bị xoá đi và thay thế bằng node mới, mất toàn bộ những gì mà node của bạn đang thực hiện (ví dụ như GKE autoscaler sẽ thay node đang sập bằng node mới sau một khoảng thời gian).

Việc Lọc và Chấm điểm sẽ được định đoạt bằng một trong hai quy cách: Thông qua các quy chế đã quy định (Policies) hoặc thông qua các profile quy chế (Profiles) nhưng trong phạm vi bài viết này, chúng ta sẽ không đề cập kĩ đến hai quy cách phức tạp trên mà sẽ xoáy vào cơ chế tài nguyên CPU và RAM.